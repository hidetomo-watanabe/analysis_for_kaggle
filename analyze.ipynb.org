{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from subprocess import check_output\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier, BaggingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR, LinearSVC, LinearSVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Analyzer(object):\n",
    "    def __init__(self):\n",
    "        self.configs = {}\n",
    "\n",
    "    def read_config_file(self, path='./config.json'):\n",
    "        with open(path, 'r') as f:\n",
    "            self.configs = json.loads(f.read())\n",
    "        self.id_col = self.configs['data']['id_col']\n",
    "        self.pred_col = self.configs['data']['pred_col']\n",
    "\n",
    "    def read_config_text(self, text):\n",
    "        self.configs = json.loads(text)\n",
    "        self.id_col = self.configs['data']['id_col']\n",
    "        self.pred_col = self.configs['data']['pred_col']\n",
    "\n",
    "    def _get_base_model(self, modelname):\n",
    "        if modelname == 'log_reg':\n",
    "            return LogisticRegression()\n",
    "        elif modelname == 'linear_reg':\n",
    "            return LinearRegression()\n",
    "        elif modelname == 'svc':\n",
    "            return SVC()\n",
    "        elif modelname == 'svr':\n",
    "            return SVR()\n",
    "        elif modelname == 'l_svc':\n",
    "            return LinearSVC()\n",
    "        elif modelname == 'l_svr':\n",
    "            return LinearSVR()\n",
    "        elif modelname == 'rf_clf':\n",
    "            return RandomForestClassifier()\n",
    "        elif modelname == 'rf_reg':\n",
    "            return RandomForestRegressor()\n",
    "        elif modelname == 'gbdt_clf':\n",
    "            return GradientBoostingClassifier()\n",
    "        elif modelname == 'gbdt_reg':\n",
    "            return GradientBoostingRegressor()\n",
    "        elif modelname == 'knn_clf':\n",
    "            return KNeighborsClassifier()\n",
    "        elif modelname == 'knn_reg':\n",
    "            return KNeighborsRegressor()\n",
    "        elif modelname == 'g_nb':\n",
    "            return GaussianNB()\n",
    "        elif modelname == 'preceptron':\n",
    "            return Perceptron()\n",
    "        elif modelname == 'sgd_clf':\n",
    "            return SGDClassifier()\n",
    "        elif modelname == 'sgd_reg':\n",
    "            return SGDRegressor()\n",
    "        elif modelname == 'dt_clf':\n",
    "            return DecisionTreeClassifier()\n",
    "        elif modelname == 'dt_reg':\n",
    "            return DecisionTreeRegressor()\n",
    "        elif modelname == 'xgb_clf':\n",
    "            return XGBClassifier()\n",
    "        elif modelname == 'xgb_reg':\n",
    "            return XGBRegressor()\n",
    "\n",
    "    def display_data(self):\n",
    "        print('### DATA LIST')\n",
    "        for label, df in [('train', self.train_df), ('test', self.test_df)]:\n",
    "            print('%s:' % label)\n",
    "            display(df.head())\n",
    "            display(df.describe())\n",
    "\n",
    "    def _replace_missing_of_dfs(self, dfs, target, target_mean):\n",
    "        replaced = False\n",
    "        output = [replaced]\n",
    "        for df in dfs:\n",
    "            for i, val in enumerate(df[target].values):\n",
    "                if math.isnan(val):\n",
    "                    replaced = True\n",
    "                    df[target].values[i] = target_mean\n",
    "            output.append(df)\n",
    "        return output\n",
    "\n",
    "    def _categorize_dfs(self, dfs, target):\n",
    "        output = []\n",
    "        all_vals = []\n",
    "        for df in dfs:\n",
    "            all_vals.extend(list(set(df[target].values)))\n",
    "        for df in dfs:\n",
    "            for val in all_vals:\n",
    "                df['%s_%s' % (target, val)] = [0] * len(df[target].values)\n",
    "            for i, val_tmp in enumerate(df[target].values):\n",
    "                for val in all_vals:\n",
    "                    if val_tmp == val:\n",
    "                        df['%s_%s' % (target, val)].values[i] = 1\n",
    "            del df[target]\n",
    "            output.append(df)\n",
    "        return output\n",
    "\n",
    "    def _to_float_of_dfs(self, dfs, pred_col, id_col):\n",
    "        output = []\n",
    "        for df in dfs:\n",
    "            for key in df.keys():\n",
    "                if key == pred_col or key == id_col:\n",
    "                    continue\n",
    "                df[key] = df[key].astype(float)\n",
    "            output.append(df)\n",
    "        return output\n",
    "\n",
    "    def get_raw_data(self):\n",
    "        train_path = self.configs['data']['train_path']\n",
    "        test_path = self.configs['data']['test_path']\n",
    "        self.train_df = pd.read_csv(train_path)\n",
    "        self.test_df = pd.read_csv(test_path)\n",
    "        return self.train_df, self.test_df\n",
    "\n",
    "    def trans_raw_data(self):\n",
    "        train_df = self.train_df\n",
    "        test_df = self.test_df\n",
    "        trans_adhoc = self.configs['translate']['adhoc']\n",
    "        # adhoc\n",
    "        if trans_adhoc['myfunc']:\n",
    "            myfunc = importlib.import_module(\n",
    "                'myfuncs.%s' % trans_adhoc['myfunc'])\n",
    "        for method_name in trans_adhoc['methods']:\n",
    "            print('adhoc: %s' % method_name)\n",
    "            train_df, test_df = eval(\n",
    "                'myfunc.%s' % method_name)([train_df, test_df], train_df)\n",
    "        # del\n",
    "        for column in self.configs['translate']['del']:\n",
    "            print('del: %s' % column)\n",
    "            del train_df[column]\n",
    "            del test_df[column]\n",
    "        # missing\n",
    "        for column in test_df.columns:\n",
    "            if test_df.dtypes[column] != 'object':\n",
    "                column_mean = train_df[column].mean()\n",
    "                replaced, train_df, test_df = self._replace_missing_of_dfs(\n",
    "                    [train_df, test_df], column, column_mean)\n",
    "                if replaced:\n",
    "                    print('missing: %s' % column)\n",
    "        # category\n",
    "        for column in test_df.columns:\n",
    "            if (\n",
    "                test_df.dtypes[column] == 'object' or\n",
    "                column in self.configs['translate']['category']\n",
    "            ):\n",
    "                print('category: %s' % column)\n",
    "                train_df, test_df = self._categorize_dfs(\n",
    "                    [train_df, test_df], column)\n",
    "        # del std=0\n",
    "        if self.configs['translate']['del_std0']:\n",
    "            for column in test_df.columns:\n",
    "                if np.std(train_df[column].values) == 0:\n",
    "                    if np.std(test_df[column].values) == 0:\n",
    "                        print('del_std0: %s' % column)\n",
    "                        del train_df[column]\n",
    "                        del test_df[column]\n",
    "        # float\n",
    "        train_df, test_df = self._to_float_of_dfs(\n",
    "            [train_df, test_df], self.pred_col, self.id_col)\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        return self.train_df, self.test_df\n",
    "\n",
    "    def get_fitting_data(self):\n",
    "        train_df = self.train_df\n",
    "        test_df = self.test_df\n",
    "        # random\n",
    "        if self.configs['data']['random']:\n",
    "            print('randomize train data')\n",
    "            train_df = train_df.iloc[np.random.permutation(len(train_df))]\n",
    "        # Y_train\n",
    "        self.Y_train = train_df[self.pred_col].values\n",
    "        # X_train\n",
    "        del train_df[self.pred_col]\n",
    "        if self.id_col in train_df.columns:\n",
    "            del train_df[self.id_col]\n",
    "        self.X_train = train_df.values\n",
    "        # X_test\n",
    "        if self.id_col in test_df.columns:\n",
    "            self.id_pred = test_df[self.id_col].values\n",
    "            del test_df[self.id_col]\n",
    "        else:\n",
    "            self.id_pred = test_df.index + 1\n",
    "        self.X_test = test_df.values\n",
    "        return self.X_train, self.Y_train, self.X_test\n",
    "\n",
    "    def normalize_fitting_data(self):\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(self.X_train)\n",
    "        self.X_train = ss.transform(self.X_train)\n",
    "        self.X_test = ss.transform(self.X_test)\n",
    "        return self.X_train, self.X_test\n",
    "\n",
    "    def is_ok_with_adversarial_validation(self):\n",
    "        def _get_adversarial_preds(X_train, X_test, adversarial):\n",
    "            # create data\n",
    "            tmp_X_train = X_train[:len(X_test)]\n",
    "            X_adv = np.concatenate((tmp_X_train, X_test), axis=0)\n",
    "            target_adv = np.concatenate(\n",
    "                (np.zeros(len(X_test)), np.ones(len(X_test))), axis=0)\n",
    "            # fit\n",
    "            gs = GridSearchCV(\n",
    "                self._get_base_model(adversarial['model']),\n",
    "                adversarial['params'],\n",
    "                cv=adversarial['cv'],\n",
    "                scoring=adversarial['scoring'],\n",
    "                n_jobs=adversarial['n_jobs'])\n",
    "            gs.fit(X_adv, target_adv)\n",
    "            est = gs.best_estimator_\n",
    "            return est.predict(tmp_X_train), est.predict(X_test)\n",
    "\n",
    "        def _is_ok_pred_nums(tr0, tr1, te0, te1):\n",
    "            if tr0 == 0 and te0 == 0:\n",
    "                return False\n",
    "            if tr1 == 0 and te1 == 0:\n",
    "                return False\n",
    "            if tr1 == 0 and te0 == 0:\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "        print('### DATA VALIDATION')\n",
    "        X_train = self.X_train\n",
    "        adversarial = self.configs['data']['adversarial']\n",
    "        if adversarial:\n",
    "            print('with adversarial')\n",
    "            adv_pred_train, adv_pred_test = _get_adversarial_preds(\n",
    "                X_train, self.X_test, adversarial)\n",
    "            adv_pred_train_num_0 = len(np.where(adv_pred_train == 0)[0])\n",
    "            adv_pred_train_num_1 = len(np.where(adv_pred_train == 1)[0])\n",
    "            adv_pred_test_num_0 = len(np.where(adv_pred_test == 0)[0])\n",
    "            adv_pred_test_num_1 = len(np.where(adv_pred_test == 1)[0])\n",
    "            print('pred train num 0: %s' % adv_pred_train_num_0)\n",
    "            print('pred train num 1: %s' % adv_pred_train_num_1)\n",
    "            print('pred test num 0: %s' % adv_pred_test_num_0)\n",
    "            print('pred test num 1: %s' % adv_pred_test_num_1)\n",
    "            if not _is_ok_pred_nums(\n",
    "                adv_pred_train_num_0,\n",
    "                adv_pred_train_num_1,\n",
    "                adv_pred_test_num_0,\n",
    "                adv_pred_test_num_1,\n",
    "            ):\n",
    "                raise Exception(\n",
    "                    '[ERROR] TRAIN AND TEST MAY BE HAVE DIFFERENT FEATURES')\n",
    "        else:\n",
    "            print('[WARN] NO DATA VALIDATION')\n",
    "            return True\n",
    "\n",
    "    def calc_best_model(self, filename):\n",
    "        print('### FIT')\n",
    "        estimators = []\n",
    "        for i, modelname in enumerate(\n",
    "            self.configs['fit']['models']\n",
    "        ):\n",
    "            base_model = self._get_base_model(modelname)\n",
    "            scoring = self.configs['fit']['scoring']\n",
    "            cv = self.configs['fit']['cv']\n",
    "            n_jobs = self.configs['fit']['n_jobs']\n",
    "            params = self.configs['fit']['params'][i]\n",
    "            gs = GridSearchCV(\n",
    "                base_model, params, cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "            gs.fit(self.X_train, self.Y_train)\n",
    "            print('modelname: %s' % modelname)\n",
    "            print('  X train shape: %s' % str(self.X_train.shape))\n",
    "            print('  Y train shape: %s' % str(self.Y_train.shape))\n",
    "            print('  best params: %s' % gs.best_params_)\n",
    "            print('  best score of trained grid search: %s' % gs.best_score_)\n",
    "            estimators.append((modelname, gs.best_estimator_))\n",
    "        # classification\n",
    "        if self.configs['fit']['mode'] == 'clf':\n",
    "            self.ensemble_model = VotingClassifier(\n",
    "                estimators=estimators,\n",
    "                weights=[1] * len(estimators),\n",
    "                voting='hard', n_jobs=n_jobs)\n",
    "        # regression\n",
    "        elif self.configs['fit']['mode'] == 'reg':\n",
    "            if len(self.configs['fit']['models']) != 1:\n",
    "                raise Exception(\n",
    "                    '[ERROR] WHEN MODE IS REG, MODEL SHOULD BE 1')\n",
    "            self.ensemble_model = BaggingRegressor(\n",
    "                base_estimator=estimators[0][1],\n",
    "                n_jobs=n_jobs)\n",
    "        self.ensemble_model = self.ensemble_model.fit(\n",
    "            self.X_train, self.Y_train)\n",
    "        print('ensemble model: %s' % self.ensemble_model)\n",
    "        with open('outputs/%s' % filename, 'wb') as f:\n",
    "            pickle.dump(self.ensemble_model, f)\n",
    "        return self.ensemble_model\n",
    "\n",
    "    def calc_output(self, filename):\n",
    "        Y_pred = self.ensemble_model.predict(self.X_test)\n",
    "        with open('outputs/%s' % filename, 'w') as f:\n",
    "            f.write('%s,%s' % (self.id_col, self.pred_col))\n",
    "            for i in range(len(self.id_pred)):\n",
    "                f.write('\\n')\n",
    "                f.write('%s,%s' % (self.id_pred[i], Y_pred[i]))\n",
    "        return filename\n",
    "\n",
    "    def visualize(self):\n",
    "        print('### SIMPLE VISUALIZATION')\n",
    "        for key in self.train_df.keys():\n",
    "            if key == self.pred_col or key == self.id_col:\n",
    "                continue\n",
    "            g = sns.FacetGrid(self.train_df, col=self.pred_col)\n",
    "            g.map(plt.hist, key, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1e1e8eda-928d-40e4-a38a-2d01c30d1fc1",
    "_execution_state": "idle",
    "_uuid": "eefd45171d68ec50244979f13ed5ba7225fb3243",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def translate_age(dfs, train_df):\n",
    "    #######################################\n",
    "    # no age => mean grouped Mr, Mrs, Miss\n",
    "    #######################################\n",
    "    # get honorific title\n",
    "    train_df['HonorificTitle'] = [''] * len(train_df['Name'].values)\n",
    "    for i, val in enumerate(train_df['Name'].values):\n",
    "        train_df['HonorificTitle'].values[i] = val.split(',')[1].split('.')[0]\n",
    "    # get honorific title => age mean\n",
    "    t2m = {}\n",
    "    tmp = train_df.groupby('HonorificTitle')['Age']\n",
    "    for key in tmp.indices.keys():\n",
    "        t2m[key] = tmp.mean()[key]\n",
    "    # age range\n",
    "    for df in dfs:\n",
    "        for i, val in enumerate(df['Age'].values):\n",
    "            if math.isnan(val):\n",
    "                val = t2m[df['Name'].values[i].split(',')[1].split('.')[0]]\n",
    "                df['Age'].values[i] = val\n",
    "    # del honorific title\n",
    "    del train_df['HonorificTitle']\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def translate_fare(dfs, train_df):\n",
    "    #######################################\n",
    "    # no fare => mean grouped by pclass\n",
    "    #######################################\n",
    "    for df in dfs:\n",
    "        for i, val in enumerate(df['Fare'].values):\n",
    "            if math.isnan(val):\n",
    "                df['Fare'].values[i] = \\\n",
    "                    train_df.groupby('Pclass')['Fare'].mean()[\n",
    "                        df['Pclass'].values[i]]\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def translate_familystatus(dfs, train_df):\n",
    "    #######################################\n",
    "    # sibsp + parch == 0 => no family(0)\n",
    "    # survive vs no survive in same familyname\n",
    "    # => more survive(1) or less survive(2)\n",
    "    # delete sibsp, parch\n",
    "    # categorize after\n",
    "    #######################################\n",
    "    # get family name\n",
    "    train_df['FamilyName'] = [''] * len(train_df['Name'].values)\n",
    "    for i, val in enumerate(train_df['Name'].values):\n",
    "        train_df['FamilyName'].values[i] = val.split(',')[0]\n",
    "    # get family name => family status\n",
    "    n2s = {}\n",
    "    tmp = train_df.groupby('FamilyName')['Survived']\n",
    "    for key in tmp.indices.keys():\n",
    "        survived_num = tmp.sum()[key]\n",
    "        no_survived_num = tmp.count()[key] - survived_num\n",
    "        if survived_num > no_survived_num:\n",
    "            n2s[key] = 1\n",
    "        else:\n",
    "            n2s[key] = 2\n",
    "    # main\n",
    "    for df in dfs:\n",
    "        df['FamilyStatus'] = [0] * len(df['Name'].values)\n",
    "        for i, val in enumerate(df['Name'].values):\n",
    "            family_name = val.split(',')[0]\n",
    "            # no family\n",
    "            if df['SibSp'].values[i] + df['Parch'].values[i] == 0:\n",
    "                continue\n",
    "            # any family\n",
    "            if family_name in n2s:\n",
    "                df['FamilyStatus'].values[i] = n2s[family_name]\n",
    "        # del sibsp, parch\n",
    "        del df['SibSp']\n",
    "        del df['Parch']\n",
    "    # del family name\n",
    "    del train_df['FamilyName']\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2c80bcc2-ebcf-4c43-bdf0-6c4299566a56",
    "_execution_state": "idle",
    "_uuid": "9b60b1203d2797ec68812ccf7c02c9e31bff718b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_text = \"\"\"\n",
    "{\n",
    "    \"data\": {\n",
    "        \"train_path\": \"/path/train.csv\",\n",
    "        \"test_path\": \"/path/test.csv\",\n",
    "        \"pred_col\": \"Hoge\",\n",
    "        \"id_col\": \"Id\",\n",
    "        \"random\": false,\n",
    "        \"adversarial\": {\n",
    "            \"model\": \"log_reg\",\n",
    "            \"scoring\": \"accuracy\",\n",
    "            \"cv\": 3,\n",
    "            \"n_jobs\": -1,\n",
    "            \"params\" : {\n",
    "                \"penalty\": [\"l1\", \"l2\"],\n",
    "                \"C\": [1, 2, 3, 4, 5]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "        \"fit\": {\n",
    "        \"models\": [\n",
    "            \"xgb_clf\",\n",
    "            \"svc\"\n",
    "        ],\n",
    "        \"scoring\": \"accuracy\",\n",
    "        \"cv\": 5,\n",
    "        \"n_jobs\": -1,\n",
    "        \"params\" : [\n",
    "            {\n",
    "                \"n_estimators\": [1, 2, 3, 4, 5],\n",
    "                \"max_depth\": [1, 2, 3, 4, 5]\n",
    "            },\n",
    "            {\n",
    "                \"probability\": [true],\n",
    "                \"C\": [1, 2, 3, 4, 5],\n",
    "                \"degree\": [1, 2, 3, 4, 5],\n",
    "                \"kernel\": [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"translate\": {\n",
    "        \"replace\": {\n",
    "            \"Hoge\": {\"hoge1\": 1, \"hoge2\": -1},\n",
    "            \"Bar\": {\"isnan\": \"mean\"}\n",
    "        },\n",
    "        \"adhoc\": {\n",
    "            \"myfunc\": \"hoge\",\n",
    "            \"methods\": [\n",
    "                \"translate_hoge\",\n",
    "                \"translate_fuga\"\n",
    "            ]\n",
    "        },\n",
    "        \"category\": [\n",
    "            \"Hoge\",\n",
    "            \"Fuga\"\n",
    "        ],\n",
    "        \"del\": [\n",
    "            \"Hoge\",\n",
    "            \"Foo\"\n",
    "        ],\n",
    "        \"del_std0\": false\n",
    "    },\n",
    "    \"notify\": {\n",
    "        \"slack\": \"https://hooks.slack.com/services/hogehoge\"\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c8e70134-2005-4d80-984a-37fa7604a47e",
    "_execution_state": "idle",
    "_uuid": "d37904a3ec4a18a302373a89e220d93c03fb8c0c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Analyzer import Analyzer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer_obj = Analyzer()\n",
    "analyzer_obj.read_config_text(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### INIT OVERVIEW')\n",
    "analyzer_obj.get_raw_data()\n",
    "analyzer_obj.display_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('### TRANSLATION OVERVIEW')\n",
    "analyzer_obj.trans_raw_data()\n",
    "analyzer_obj.display_data()\n",
    "analyzer_obj.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer_obj.get_fitting_data()\n",
    "analyzer_obj.normalize_fitting_data()\n",
    "analyzer_obj.is_ok_with_adversarial_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer_obj.calc_best_model('tmp.pickle')\n",
    "analyzer_obj.calc_output('tmp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
