{
  "nbformat": 4,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "version": "3.6.1",
      "file_extension": ".py",
      "name": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "c8e70134-2005-4d80-984a-37fa7604a47e",
        "collapsed": true,
        "_execution_state": "idle",
        "_uuid": "d37904a3ec4a18a302373a89e220d93c03fb8c0c"
      },
      "source": [
        "import math\n",
        "import json\n",
        "import configparser\n",
        "# import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from subprocess import check_output\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "1e1e8eda-928d-40e4-a38a-2d01c30d1fc1",
        "collapsed": true,
        "_execution_state": "idle",
        "_uuid": "eefd45171d68ec50244979f13ed5ba7225fb3243"
      },
      "source": [
        "def get_base_model(modelname):\n",
        "    if modelname == 'log_reg':\n",
        "        return LogisticRegression()\n",
        "    elif modelname == 'svc':\n",
        "        return SVC()\n",
        "    elif modelname == 'l_svc':\n",
        "        return LinearSVC()\n",
        "    elif modelname == 'rf_clf':\n",
        "        return RandomForestClassifier()\n",
        "    elif modelname == 'gbdt_clf':\n",
        "        return GradientBoostingClassifier()\n",
        "    elif modelname == 'knn_clf':\n",
        "        return KNeighborsClassifier()\n",
        "    elif modelname == 'g_nb':\n",
        "        return GaussianNB()\n",
        "    elif modelname == 'preceptron':\n",
        "        return Perceptron()\n",
        "    elif modelname == 'sgd_clf':\n",
        "        return SGDClassifier()\n",
        "    elif modelname == 'dt_clf':\n",
        "        return DecisionTreeClassifier()\n",
        "\n",
        "    \n",
        "def display_dfs(dfs):\n",
        "    for df in dfs:\n",
        "        display(df.head())\n",
        "        display(df.describe())\n",
        "\n",
        "\n",
        "def replace_dfs(dfs, target, config, *, mean=None):\n",
        "    \"\"\"\n",
        "        config is dict\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    for df in dfs:\n",
        "        for i, value1 in enumerate(df[target].values):\n",
        "            for key, value2 in config.items():\n",
        "                # mean\n",
        "                if value2 == 'mean':\n",
        "                    value2 = mean\n",
        "                # translate\n",
        "                if key == 'isnan':\n",
        "                    if math.isnan(value1):\n",
        "                        df[target].values[i] = value2\n",
        "                else:\n",
        "                    if value1 == key:\n",
        "                        df[target].values[i] = value2\n",
        "        output.append(df)\n",
        "    return output\n",
        "\n",
        "\n",
        "def categorize_dfs(dfs, target, config):\n",
        "    \"\"\"\n",
        "        config is list\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    for df in dfs:\n",
        "        for value2 in config:\n",
        "            df['%s_%s' % (target, value2)] = [0] * len(df[target].values)\n",
        "        for i, value1 in enumerate(df[target].values):\n",
        "            for value2 in config:\n",
        "                if value1 == value2:\n",
        "                    df['%s_%s' % (target, value2)].values[i] = 1\n",
        "        del df[target]\n",
        "        output.append(df)\n",
        "    return output\n",
        "\n",
        "\n",
        "def to_float_dfs(dfs, pred_col, id_col):\n",
        "    output = []\n",
        "    for df in dfs:\n",
        "        for key in df.keys():\n",
        "            if key == pred_col or key == id_col:\n",
        "                continue\n",
        "            df[key] = df[key].astype(float)\n",
        "        output.append(df)\n",
        "    return output\n",
        "\n",
        "\n",
        "def translate_age(dfs, train_df):\n",
        "    #######################################\n",
        "    # no age => mean grouped Mr, Mrs, Miss\n",
        "    #######################################\n",
        "    # get honorific title\n",
        "    train_df['HonorificTitle'] = [''] * len(train_df['Name'].values)\n",
        "    for i, val in enumerate(train_df['Name'].values):\n",
        "        train_df['HonorificTitle'].values[i] = val.split(',')[1].split('.')[0]\n",
        "    # get honorific title => age mean\n",
        "    t2m = {}\n",
        "    tmp = train_df.groupby('HonorificTitle')['Age']\n",
        "    for key in tmp.indices.keys():\n",
        "        t2m[key] = tmp.mean()[key]\n",
        "    # age range\n",
        "    for df in dfs:\n",
        "        for i, val in enumerate(df['Age'].values):\n",
        "            if math.isnan(val):\n",
        "                val = t2m[df['Name'].values[i].split(',')[1].split('.')[0]]\n",
        "                df['Age'].values[i] = val\n",
        "    # del honorific title\n",
        "    del train_df['HonorificTitle']\n",
        "    return dfs\n",
        "\n",
        "\n",
        "def translate_familystatus(dfs, train_df):\n",
        "    #######################################\n",
        "    # sibsp + parch == 0 => no family(0)\n",
        "    # survive vs no survive in same familyname\n",
        "    # => more survive(1) or less survive(2)\n",
        "    # categorize after\n",
        "    #######################################\n",
        "    # get family name\n",
        "    train_df['FamilyName'] = [''] * len(train_df['Name'].values)\n",
        "    for i, val in enumerate(train_df['Name'].values):\n",
        "        train_df['FamilyName'].values[i] = val.split(',')[0]\n",
        "    # get family name => family status\n",
        "    n2s = {}\n",
        "    tmp = train_df.groupby('FamilyName')['Survived']\n",
        "    for key in tmp.indices.keys():\n",
        "        survived_num = tmp.sum()[key]\n",
        "        no_survived_num = tmp.count()[key] - survived_num\n",
        "        if survived_num > no_survived_num:\n",
        "            n2s[key] = 1\n",
        "        else:\n",
        "            n2s[key] = 2\n",
        "    # main\n",
        "    for df in dfs:\n",
        "        df['FamilyStatus'] = [0] * len(df['Name'].values)\n",
        "        for i, val in enumerate(df['Name'].values):\n",
        "            family_name = val.split(',')[0]\n",
        "            # no family\n",
        "            if df['SibSp'].values[i] + df['Parch'].values[i] == 0:\n",
        "                continue\n",
        "            # any family\n",
        "            if family_name in n2s:\n",
        "                df['FamilyStatus'].values[i] = n2s[family_name]\n",
        "    # del family name\n",
        "    del train_df['FamilyName']\n",
        "    return dfs"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "2c80bcc2-ebcf-4c43-bdf0-6c4299566a56",
        "_execution_state": "idle",
        "_uuid": "9b60b1203d2797ec68812ccf7c02c9e31bff718b"
      },
      "source": [
        "# definition\n",
        "# for jupyter\n",
        "config_txt = \"\"\"\n",
        "[data]\n",
        "path = ../input\n",
        "pred_col = hoge\n",
        "id_col = hoge\n",
        "train_num =\n",
        "\n",
        "[model]\n",
        "base = gbdt_clf\n",
        "scoring = accuracy\n",
        "cv = 3\n",
        "params = {\n",
        "    \"n_estimators\": [1, 2, 3, 4, 5],\n",
        "    \"max_depth\": [1, 2, 3, 4, 5]\n",
        "    }\n",
        "\n",
        "[translate]\n",
        "replace = {\n",
        "    }\n",
        "adhoc = [\n",
        "    \"translate_hoge\",\n",
        "    \"translate_hoge2\"\n",
        "    ]\n",
        "category = {\n",
        "    \"a\": [\"hoge1\", \"hoge2\"],\n",
        "    \"b\": [1, 2, 3],\n",
        "    \"c\": [0, 1, 2]\n",
        "    }\n",
        "del = [\n",
        "    \"hoge\",\n",
        "    \"fuga\"\n",
        "    ]\n",
        "\"\"\"\n",
        "\n",
        "cp = configparser.SafeConfigParser()\n",
        "cp.read_string(config_txt)\n",
        "# data\n",
        "data_path = cp.get('data', 'path')\n",
        "pred_col = cp.get('data', 'pred_col')\n",
        "id_col = cp.get('data', 'id_col')\n",
        "train_num = cp.get('data', 'train_num')\n",
        "if train_num:\n",
        "    train_num = int(train_num)\n",
        "else:\n",
        "    train_num = None\n",
        "# model\n",
        "base_model = get_base_model(cp.get('model', 'base'))\n",
        "scoring = cp.get('model', 'scoring')\n",
        "cv = cp.getint('model', 'cv')\n",
        "params = json.loads(cp.get('model', 'params'))\n",
        "# traslate\n",
        "trans_adhoc = json.loads(cp.get('translate', 'adhoc'))\n",
        "trans_replace = json.loads(cp.get('translate', 'replace'))\n",
        "trans_del = json.loads(cp.get('translate', 'del'))\n",
        "trans_category = json.loads(cp.get('translate', 'category'))"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "30712a21-b54e-44f8-b38e-ca92dad0842b",
        "_execution_state": "idle",
        "_uuid": "e90817eca64d76e6c80164c788d68eb2e238c5b9"
      },
      "source": [
        "# data list\n",
        "print('### DATA LIST')\n",
        "print(check_output(['ls', data_path]).decode('utf8'))\n",
        "train_df = pd.read_csv('%s/train.csv' % data_path)\n",
        "test_df = pd.read_csv('%s/test.csv' % data_path)"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "df8c5665-d1da-40cb-8a6e-feea1d6eecac",
        "_execution_state": "idle",
        "_uuid": "f724473d29fe444c776572c7860fc6a01779e9e2"
      },
      "source": [
        "# init overview\n",
        "print('### INIT OVERVIEW')\n",
        "display_dfs([train_df, test_df])"
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "01ed463c-b0b7-4b1e-9b7f-27b64709fe53",
        "collapsed": true,
        "_execution_state": "idle",
        "_uuid": "96251e7e2daba5565a16be2a0af7a6c47f7315d4"
      },
      "source": [
        "# data translation\n",
        "# replace\n",
        "for key, value in trans_replace.items():\n",
        "    # mean\n",
        "    if train_df.dtypes[key] == 'object':\n",
        "        key_mean = None\n",
        "    else:\n",
        "        key_mean = train_df[key].mean()\n",
        "    train_df, test_df = replace_dfs(\n",
        "        [train_df, test_df], key, value, mean=key_mean)\n",
        "# adhoc\n",
        "for value in trans_adhoc:\n",
        "    train_df, test_df = eval(\n",
        "        '%s' % value)([train_df, test_df], train_df)\n",
        "# category\n",
        "for key, values in trans_category.items():\n",
        "    train_df, test_df = categorize_dfs([train_df, test_df], key, values)\n",
        "# del\n",
        "for value in trans_del:\n",
        "    del train_df[value]\n",
        "    del test_df[value]\n",
        "# float\n",
        "train_df, test_df = to_float_dfs([train_df, test_df], pred_col, id_col)"
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "89566a3d-28b9-4c66-b8a5-f3c4e6251b30",
        "_execution_state": "idle",
        "_uuid": "86dcb408c27f798cd4ed1ca5a204fa7c87cc2253"
      },
      "source": [
        "# translation overview\n",
        "print('### TRANSLATION OVERVIEW')\n",
        "display_dfs([train_df, test_df])"
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "9ccae323-e19f-42f5-9d18-00d00dd78933",
        "_execution_state": "idle",
        "_uuid": "2101c8baad28dcc610f849e0d863d93a909f74f8"
      },
      "source": [
        "# simple visualization\n",
        "print('### SIMPLE VISUALIZATION')\n",
        "for key in train_df.keys():\n",
        "    if key == pred_col or key == id_col:\n",
        "        continue\n",
        "    g = sns.FacetGrid(train_df, col=pred_col)\n",
        "    g.map(plt.hist, key, bins=20)"
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "686b8117-d4dd-4ebf-8e7b-88bd228f9a99",
        "collapsed": true,
        "_execution_state": "idle",
        "_uuid": "d2a417084d1b3724999b4f04f701aeea2ed60d53"
      },
      "source": [
        "# create ndarray\n",
        "Y_train = train_df[pred_col].values\n",
        "id_pred = test_df[id_col].values\n",
        "del train_df[pred_col]\n",
        "del train_df[id_col]\n",
        "del test_df[id_col]\n",
        "X_train = train_df.values\n",
        "X_test = test_df.values"
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "b5bc255f-c8d8-44d0-af17-5ae80c3856c6",
        "collapsed": true,
        "_execution_state": "idle",
        "_uuid": "47a2c241ba153f15232195bbf286a67769ac7a29"
      },
      "source": [
        "# translate ndarray to standard\n",
        "ss = StandardScaler()\n",
        "ss.fit(X_train)\n",
        "X_train = ss.transform(X_train)\n",
        "X_test = ss.transform(X_test)"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "3df58bf8-0db4-401f-932e-45e35a008eed",
        "_execution_state": "idle",
        "_uuid": "a35da94996953b6cfc84701078ffc7a663e9b994"
      },
      "source": [
        "# fit\n",
        "print('### FIT')\n",
        "gs = GridSearchCV(base_model, params, cv=cv, scoring=scoring, n_jobs=-1)\n",
        "if train_num:\n",
        "    print('train num: %s' % train_num)\n",
        "    gs.fit(X_train[:train_num], Y_train[:train_num])\n",
        "else:\n",
        "    print('train num: ALL(%s)' % len(X_train))\n",
        "    gs.fit(X_train, Y_train)\n",
        "print('X train shape: %s' % str(X_train.shape))\n",
        "print('Y train shape: %s' % str(Y_train.shape))\n",
        "print('best params: %s' % gs.best_params_)\n",
        "print('best score of trained grid search: %s' % gs.best_score_)\n",
        "if train_num:\n",
        "    print(\n",
        "        'best score of not trained data: %s' %\n",
        "        gs.score(X_train[train_num:], Y_train[train_num:]))\n",
        "best_model = gs.best_estimator_\n",
        "print('best model: %s' % best_model)"
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "_cell_guid": "0d49611f-7755-4ef7-a1e7-4f4b9b67075c",
        "_execution_state": "idle",
        "_uuid": "611fa35b9f6ba8b2d0df09946f7f0ffbbb1b0a91"
      },
      "source": [
        "# predict and create output\n",
        "Y_pred = best_model.predict(X_test)\n",
        "print('%s,%s' % (id_col, pred_col))\n",
        "for i in range(len(id_pred)):\n",
        "    print('%s,%s' % (id_pred[i], Y_pred[i]))"
      ],
      "execution_count": 12
    }
  ],
  "nbformat_minor": 1
}
